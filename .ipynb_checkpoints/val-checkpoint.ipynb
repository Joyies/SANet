{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import cv2\n",
    "import scipy.io as io\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage.filters import gaussian_filter \n",
    "import scipy\n",
    "import json\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from matplotlib import cm as CM\n",
    "from model import SANet\n",
    "import torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now generate the ShanghaiA's ground truth\n",
    "part_A_train = os.path.join(root,'part_A_final/train_data','images')\n",
    "part_A_test = os.path.join(root,'part_A_final/test_data','images')\n",
    "part_B_train = os.path.join(root,'part_B_final/train_data','images')\n",
    "part_B_test = os.path.join(root,'part_B_final/test_data','images')\n",
    "path_sets = [part_A_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = []\n",
    "for path in path_sets:\n",
    "    for img_path in glob.glob(os.path.join(path, '*.jpg')):\n",
    "        img_paths.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SANet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('0model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_density(den,patch_idx,patch):\n",
    "    patch_size = np.shape(patch)\n",
    "    den_size = np.shape(den)\n",
    "#     print(np.shape(den))\n",
    "#     print(patch_size)\n",
    "#     print(patch_idx)\n",
    "    #axis in density map\n",
    "    dx = int(patch_idx%3)*int(patch_size[1]/2)\n",
    "    dy = int(patch_idx/3)*int(patch_size[0]/2)\n",
    "\n",
    "    dx_len = int(patch_size[1]*(3/4))\n",
    "    dy_len = int(patch_size[0]*(3/4))\n",
    "    #axis in patch\n",
    "    px = 0\n",
    "    py = 0 \n",
    "    px_len = int(patch_size[1]*(3/4))\n",
    "    py_len = int(patch_size[0]*(3/4))\n",
    "    \n",
    "    if dx!=0:\n",
    "        dx = dx+int(patch_size[1]/4)\n",
    "        px = int(patch_size[1]/4)\n",
    "    if dx!=0 and dx+dx_len!=den_size[1]:\n",
    "        dx_len = int(patch_size[1]/2)\n",
    "        px_len = int(patch_size[1]/2)\n",
    "    if dy!=0:\n",
    "        dy = dy+int(patch_size[0]/4)\n",
    "        py = int(patch_size[0]/4)\n",
    "    if dy!=0 and dy+dy_len!=den_size[0]:\n",
    "        dy_len = int(patch_size[0]/2)\n",
    "        py_len = int(patch_size[0]/2)\n",
    "        \n",
    "#     print(dx,dy,dx_len,dy_len)\n",
    "#     print(px,py,px_len,py_len)\n",
    "        \n",
    "    den[dy:dy+dy_len,dx:dx+dx_len] = patch[py:py+py_len,px:px+px_len]\n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_transform=transforms.Compose([\n",
    "   transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "    \n",
    "toTensor_transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mae = 0\n",
    "for i in range(len(img_paths)):\n",
    "    img = Image.open(img_paths[i]).convert('RGB')\n",
    "    gt_file = h5py.File(img_paths[i].replace('.jpg','.h5').replace('images','ground_truth'),'r')\n",
    "    groundtruth = np.asarray(gt_file['density'])\n",
    "    \n",
    "    img = img.crop((0,0,int(img.size[0]/16)*16,int(img.size[1]/16)*16))\n",
    "    target = groundtruth[0:img.size[1],0:img.size[0]]\n",
    "    \n",
    "    img = std_transform(img)\n",
    "    img = transforms.ToPILImage()(img).convert('RGB') \n",
    "\n",
    "    den = np.zeros(np.shape(target))\n",
    "    crop_size = (int(img.size[0]/2),int(img.size[1]/2))\n",
    "    \n",
    "    for j in range(9):\n",
    "        dx = int((j%3)*crop_size[0])\n",
    "        dy = int((j/3)*crop_size[1])\n",
    "        patch = img.crop((dx,dy,crop_size[0]+dx,crop_size[1]+dy))\n",
    "        patch = toTensor_transform(patch)\n",
    "        patch = patch.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(patch.unsqueeze(0))  \n",
    "            output = output.squeeze().detach().cpu().numpy()\n",
    "        combine_density(den,j,output)\n",
    "        \n",
    "    den_show = 255*den/np.max(den)\n",
    "    cv2.imshow('Result', den_show)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    mae += abs(np.sum(den)-np.sum(target))\n",
    "    print(i,mae)\n",
    "print(mae/len(img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
