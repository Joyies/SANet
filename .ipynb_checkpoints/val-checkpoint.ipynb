{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mask/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import cv2\n",
    "import scipy.io as io\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage.filters import gaussian_filter \n",
    "import scipy\n",
    "import json\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from matplotlib import cm as CM\n",
    "from model import SANet\n",
    "import torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now generate the ShanghaiA's ground truth\n",
    "part_A_train = os.path.join(root,'part_A_final/train_data','images')\n",
    "part_A_test = os.path.join(root,'part_A_final/test_data','images')\n",
    "part_B_train = os.path.join(root,'part_B_final/train_data','images')\n",
    "part_B_test = os.path.join(root,'part_B_final/test_data','images')\n",
    "path_sets = [part_A_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = []\n",
    "for path in path_sets:\n",
    "    for img_path in glob.glob(os.path.join(path, '*.jpg')):\n",
    "        img_paths.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SANet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('0model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_density(den,patch_idx,patch):\n",
    "    patch_size = np.shape(patch)\n",
    "    den_size = np.shape(den)\n",
    "#     print(np.shape(den))\n",
    "#     print(patch_size)\n",
    "#     print(patch_idx)\n",
    "    #axis in density map\n",
    "    #x for verticle y for horizon\n",
    "    dx = int(patch_idx/3)*int(patch_size[0]/2)\n",
    "    dy = int(patch_idx%3)*int(patch_size[1]/2)\n",
    "\n",
    "    dx_len = int(patch_size[0]*(3/4))\n",
    "    dy_len = int(patch_size[1]*(3/4))\n",
    "    #axis in patch\n",
    "    px = 0\n",
    "    py = 0 \n",
    "    px_len = int(patch_size[0]*(3/4))\n",
    "    py_len = int(patch_size[1]*(3/4))\n",
    "    \n",
    "    if dx!=0:\n",
    "        dx = dx+int(patch_size[0]/4)\n",
    "        px = int(patch_size[0]/4)\n",
    "    if dx!=0 and dx+dx_len!=den_size[0]:\n",
    "        dx_len = int(patch_size[0]/2)\n",
    "        px_len = int(patch_size[0]/2)\n",
    "    if dy!=0:\n",
    "        dy = dy+int(patch_size[1]/4)\n",
    "        py = int(patch_size[1]/4)\n",
    "    if dy!=0 and dy+dy_len!=den_size[1]:\n",
    "        dy_len = int(patch_size[1]/2)\n",
    "        py_len = int(patch_size[1]/2)\n",
    "        \n",
    "#     print(dx,dy,dx_len,dy_len)\n",
    "#     print(px,py,px_len,py_len)\n",
    "        \n",
    "    den[dx:dx+dx_len,dy:dy+dy_len] = patch[px:px+px_len,py:py+py_len]\n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_transform=transforms.Compose([\n",
    "   transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "    \n",
    "toTensor_transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 570.948438141495\n",
      "1 882.9061740785837\n",
      "2 993.1059974581003\n",
      "3 1152.975809276104\n",
      "4 1815.676839210093\n",
      "5 1821.0034383684397\n",
      "6 2262.5125967524946\n",
      "7 2372.5720016509295\n",
      "8 2407.6505537629128\n",
      "9 2454.630161974579\n",
      "10 2916.524280872196\n",
      "11 2955.2176080569625\n",
      "12 2977.0551643520594\n",
      "13 3787.69245165959\n",
      "14 4153.519266646355\n",
      "15 4545.501230895519\n",
      "16 4684.662564378232\n",
      "17 4702.412452254444\n",
      "18 5059.013202816248\n",
      "19 5745.9285452999175\n",
      "20 6381.044996872544\n",
      "21 6408.308338612318\n",
      "22 6540.168348748237\n",
      "23 7513.949291855097\n"
     ]
    }
   ],
   "source": [
    "mae = 0\n",
    "for i in range(len(img_paths)):\n",
    "    img = Image.open(img_paths[i]).convert('RGB')\n",
    "    img = img.crop((0,0,int(img.size[0]/16)*16,int(img.size[1]/16)*16))\n",
    "    gt_file = h5py.File(img_paths[i].replace('.jpg','.h5').replace('images','ground_truth'),'r')\n",
    "    groundtruth = np.asarray(gt_file['density'])\n",
    "    \n",
    "    img = img.crop((0,0,int(img.size[0]/16)*16,int(img.size[1]/16)*16))\n",
    "    target = groundtruth[0:img.size[1],0:img.size[0]]\n",
    "    \n",
    "    img = std_transform(img)\n",
    "    img = transforms.ToPILImage()(img).convert('RGB') \n",
    "\n",
    "    den = np.zeros(np.shape(target))\n",
    "    crop_size = (int(img.size[0]/2),int(img.size[1]/2))\n",
    "    \n",
    "    for j in range(9):\n",
    "        dx = int((j/3)*crop_size[0])\n",
    "        dy = int((j%3)*crop_size[1])\n",
    "        patch = img.crop((dx,dy,crop_size[0]+dx,crop_size[1]+dy))\n",
    "        patch = toTensor_transform(patch)\n",
    "        patch = patch.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(patch.unsqueeze(0))  \n",
    "            output = output.squeeze().detach().cpu().numpy()\n",
    "        combine_density(den,j,output)\n",
    "        \n",
    "    den_show = 255*den/np.max(den)\n",
    "    cv2.imshow('Result', den_show)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    mae += abs(np.sum(den)-np.sum(target))\n",
    "    print(i,mae)\n",
    "print(mae/len(img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
